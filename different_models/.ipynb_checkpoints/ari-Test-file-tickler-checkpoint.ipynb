{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/miniconda3/envs/stats/lib/python3.9/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "from zipfile import ZipFile\n",
    "# Local clustering class with a bunch of methods\n",
    "from numpy.ma.core import nonzero\n",
    "os.chdir(\"/scratch/nick/MSMC-Curve-Analysis\")\n",
    "# Data thingy libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as snsariTesting\n",
    "\n",
    "from tslearn.generators import random_walks\n",
    "import matplotlib.cm as cm\n",
    "import json \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import kneed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "# from sklearn.metrics import silhouette_score\n",
    "from tslearn.clustering import silhouette_score\n",
    "\n",
    "from MSMC_clustering import Msmc_clustering\n",
    "import MSMC_clustering as mc\n",
    "import Silhouette_analysis as sa\n",
    "\n",
    "# Load in precomputed list of files to filter out (Saves time)\n",
    "# Consider making the sharpness filter on percent too\n",
    "regular_path = \"lenient-curve-filter\"\n",
    "filter_path = \"MSMC-Exploratory-Analysis/results/figures/filtered-out-curves\"\n",
    "kept_path = \"MSMC-Exploratory-Analysis/results/figures/kept-curves\"\n",
    "\n",
    "omit_list_path = \"MSMC-Exploratory-Analysis/results/lists\"\n",
    "omit_test_lenient_file = \"omit_test_lenient.txt\"\n",
    "kept_test_lenient_file = \"kept_test_lenient.txt\"\n",
    "\n",
    "if omit_test_lenient_file not in os.listdir(omit_list_path):\n",
    "    omit_test_lenient = filter_flattness_sharpness(cluster_rt, \n",
    "                        identical_val_threshold = 0.7, err = 0.01, # Args for filtering flattness\n",
    "                        magnitude_jump_threshold = 0.95, points_per_jump = 3, # Args for filtering magnitude jumps\n",
    "                        plot = True, min_unique_vals=999, ignore_low_mag=0, \n",
    "                        fs_x=10, fs_y=9, save_to_filter=filter_path, save_to_kept=kept_path) # These are some pretty good settings\n",
    "    with open(omit_list_path+\"/\"+omit_test_lenient_file, \"w\") as myFile:\n",
    "        for fileName in omit_test_lenient:\n",
    "            myFile.write(f\"{fileName}\\n\")\n",
    "\n",
    "else: # If list exists\n",
    "    omit_test_lenient = [] # List of names to files which were filtered out due to being elboq shaped\n",
    "    with open(omit_list_path+\"/\"+omit_test_lenient_file, \"r\") as myFile:\n",
    "        for line in myFile:\n",
    "            omit_test_lenient.append(line.rstrip())\n",
    "\n",
    "kept_test_lenient = [] # List of names to files which were kept\n",
    "for jpg_name in os.listdir(kept_path):\n",
    "    jpg_name = jpg_name[:-4] # assuming that all files in \"kept_path\" are .jpgs and end with the specifier \".jpg\"\n",
    "    kept_test_lenient.append(jpg_name)\n",
    "\n",
    "# List of latin names is useful for indexing on metadata dfs later on\n",
    "omit_test_lenient_latin = [name[:name.index(\"_GC\")] for name in omit_test_lenient] \n",
    "kept_test_lenient_latin = [name[:name.index(\"_GC\")] for name in kept_test_lenient]\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def writeList(save_to, inlist):\n",
    "    with open(save_to, \"w\") as f:\n",
    "        for x in inlist:\n",
    "            f.write(x+\"\\n\")\n",
    "    return\n",
    "            \n",
    "def readList(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        output = []\n",
    "        for x in f:\n",
    "            x = x.rstrip(\"\\n\")\n",
    "            output.append(x)\n",
    "    return output\n",
    "\n",
    "def label2subtable(table, label):\n",
    "    res = table[table[\"Labels\"]==label]\n",
    "    return res\n",
    "\n",
    "def ARI_consistency_test(algo: \"str\",\n",
    "                         to_omit: \"list<str>\",\n",
    "                         iters: \"int\",\n",
    "                         gammas: \"list<int>\",\n",
    "                         clusts: \"list<int>\",\n",
    "                         oldSeed: \"int\",\n",
    "                         newSeeds: \"list<int>\",\n",
    "                         save_to: \"bool/str\"=False)->\"dict\":\n",
    "    '''\n",
    "    Does pairwise comparisons between a reference clustering (using oldSeed)\n",
    "    and various other clusterings (using newSeeds). Includes option of taking\n",
    "    in list of sample names (full file name of sample) as items to omit.\n",
    "    \n",
    "    Clusterings can be done over a range of gammas (if using softdtw) and over\n",
    "    a range of manual clustering sizes\n",
    "    '''\n",
    "    seeds=newSeeds\n",
    "    by_gamma_dict = dict() # Contains [old_seed_dict, new_seed_dict, randi_dict]\n",
    "    for gamma in gammas:\n",
    "        old_seed_dict = {clust : [] for clust in clusts}\n",
    "        new_seed_dict = {clust : [] for clust in clusts}\n",
    "        randi_dict =    {clust : [] for clust in clusts}\n",
    "        new_clusters = {clust : dict() for clust in clusts}\n",
    "        old_clusters = {clust : dict() for clust in clusts}\n",
    "        for clust in clusts:\n",
    "            cluster_rt_norm_lenient_og = Msmc_clustering(directory=\"msmc_curve_data/\", \n",
    "                                                    mu=1.4e-9, \n",
    "                                                    generation_time_path='generation_lengths/', \n",
    "                                                    real_time=True, \n",
    "                                                    to_omit=to_omit,\n",
    "                                                    normalize_lambda=True, \n",
    "                                                    log_scale_time=True, \n",
    "                                                    plot_on_log_scale=True, \n",
    "                                                    exclude_subdirs=[\"Archive\", \"mammals_part_1\"], \n",
    "                                                    manual_cluster_count=clust,\n",
    "                                                    algo=algo) # cluster count by sqrt method is 14\n",
    "            cluster_rt_norm_lenient_og.cluster_curves(omit_front=0, \n",
    "                                                      omit_back=0, \n",
    "                                                      cols=4,  \n",
    "                                                      fs_x=60, \n",
    "                                                      fs_y=30,\n",
    "                                                      metric_params={\"gamma\" : gamma},\n",
    "                                                      metric=\"softdtw\",\n",
    "                                                      random_state=oldSeed,\n",
    "                                                      plot_everything=True,\n",
    "                                                      iter=iters)\n",
    "            for seed in seeds:\n",
    "                cluster_rt_norm_lenient = Msmc_clustering(directory=\"msmc_curve_data/\", \n",
    "                                                        mu=1.4e-9, \n",
    "                                                        generation_time_path='generation_lengths/', \n",
    "                                                        real_time=True, \n",
    "                                                        to_omit=to_omit,\n",
    "                                                        normalize_lambda=True, \n",
    "                                                        log_scale_time=True, \n",
    "                                                        plot_on_log_scale=True, \n",
    "                                                        exclude_subdirs=[\"Archive\", \"mammals_part_1\"], \n",
    "                                                        manual_cluster_count=clust,\n",
    "                                                        algo=algo) # cluster count by sqrt method is 14\n",
    "\n",
    "                cluster_rt_norm_lenient.cluster_curves(omit_front=0, \n",
    "                                                       omit_back=0, \n",
    "                                                       cols=4,  \n",
    "                                                       fs_x=60, \n",
    "                                                       fs_y=30,\n",
    "                                                       metric_params={\"gamma\" : gamma},\n",
    "                                                       metric=\"softdtw\",\n",
    "                                                       random_state=seed,\n",
    "                                                       plot_everything=True,\n",
    "                                                       iter=iters)\n",
    "\n",
    "                old = cluster_rt_norm_lenient_og.dtw_labels\n",
    "                old_seed_dict[clust].append(old)\n",
    "\n",
    "                new = cluster_rt_norm_lenient.dtw_labels\n",
    "                new_seed_dict[clust].append(new)\n",
    "                randi_dict[clust].append(adjusted_rand_score(old, new))\n",
    "                new_clusters[clust][seed] = cluster_rt_norm_lenient\n",
    "                print(f\"[RAND INDEX]: Random seed comparison of {clust} clusters: {adjusted_rand_score(old, new)}\")\n",
    "            old_clusters[clust][oldSeed] = cluster_rt_norm_lenient_og\n",
    "        by_gamma_dict[gamma] = [old_seed_dict, new_seed_dict, randi_dict, old_clusters, new_clusters]\n",
    "        if save_to:\n",
    "            pickle.dump(by_gamma_dict, open(save_to, 'wb'))\n",
    "    return by_gamma_dict\n",
    "\n",
    "def badVoteCounter(ARI_consistency_test_dict: \"dict\",\n",
    "                   clust: \"int\",\n",
    "                   oldSeed: \"int\",\n",
    "                   newSeeds: \"list<int>\",\n",
    "                   gamma=0.0,\n",
    "                   savefig_to=False,\n",
    "                   savepkl_to=False)->\"dict\":\n",
    "    '''\n",
    "    I have seriesDict which is {name: series}\n",
    "\n",
    "    We have a constant clustering and compare it to N number of random clusterings.\n",
    "\n",
    "    I will need to separate samples by cluster.\n",
    "    I add votes to samples for each difference that their constant clustering has\n",
    "    with each new clustering.\n",
    "\n",
    "    For each sample in old cluster\n",
    "        Find clustermates of old sample\n",
    "        For same sample in new cluster\n",
    "            Find clustermates of old sample in new cluster\n",
    "            Count the number of differences between old and new cluster\n",
    "            Map count of differences to sample name\n",
    "    '''\n",
    "    seeds = newSeeds\n",
    "    old_clusters = ARI_consistency_test_dict[gamma][-2]\n",
    "    new_clusters = ARI_consistency_test_dict[gamma][-1]\n",
    "    old = old_clusters[clust][oldSeed]\n",
    "    oldSampleNames = old.namesofMySeries\n",
    "    badVoteCount = {sample: 0 for sample in oldSampleNames}\n",
    "    for oldSampleName in oldSampleNames:\n",
    "        oldSampleKey = oldSampleName[:oldSampleName.index(\"_GC\")] # Latin name\n",
    "        oldSampleLabel = old.clusterTable.loc[oldSampleKey][\"Labels\"]\n",
    "        oldMates = label2subtable(old.clusterTable, oldSampleLabel) # Clustermates of old sample\n",
    "\n",
    "        for seed in seeds:\n",
    "            new = new_clusters[clust][seed]\n",
    "            newSampleNames = new.namesofMySeries\n",
    "            newSampleLabel = new.clusterTable.loc[oldSampleKey][\"Labels\"] # w cluster assignment of old sample\n",
    "            newMates = label2subtable(new.clusterTable, newSampleLabel)\n",
    "\n",
    "            difference = list(set(newMates.index) - set(oldMates.index))\n",
    "            badVoteCount[oldSampleName] += len(difference)\n",
    "\n",
    "    x, y = zip(*sorted(badVoteCount.items(), key = lambda x:x[1]))\n",
    "    fig = plt.figure(figsize = (40, 40))\n",
    "    plt.barh(x, y)\n",
    "    if savefig_to and savepkl_to:\n",
    "        plt.savefig(savefig_to)\n",
    "        pickle.dump(badVoteCount, open(savepkl_to, 'wb'))\n",
    "    return badVoteCount\n",
    "\n",
    "def voteOutMovingSample(badVoteCount: \"dict\",\n",
    "                        lower_cutoff: \"float\" = 0.0,\n",
    "                        cutoff_last: \"bool/int\" = False,\n",
    "                        save_to: \"str\"=False)-> \"list\":\n",
    "    # Sort vote dict items by votes (bad samples have many votes)\n",
    "    x, y = zip(*sorted(badVoteCount.items(), key = lambda x:x[1]))\n",
    "    y = np.array(y)\n",
    "    if cutoff_last:\n",
    "        newOmit = list(x[-cutoff_last:])\n",
    "    else:\n",
    "        newOmit = list(x[-len(y[y>lower_cutoff]):]) # Samples with more votes\n",
    "    newOmit = list(set(newOmit))\n",
    "    if save_to:\n",
    "        writeList(save_to, newOmit)\n",
    "    return newOmit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6b90f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'ARI_consistency_test3.py',\n",
       " 'ARI_consistency_test.py',\n",
       " 'data',\n",
       " 'generation_lengths',\n",
       " 'random_dropout.py',\n",
       " 'zips',\n",
       " 'MSMC-Exploratory-Analysis',\n",
       " 'Todo.docx',\n",
       " 'jupyterthemes_editor.ipynb',\n",
       " 'ucr_ts_data',\n",
       " 'ARI_consistency_test2.py',\n",
       " 'random_dropout2.py',\n",
       " 'random_dropout3.py',\n",
       " 'MSMC_clustering.py',\n",
       " 'UCRArchive_2018',\n",
       " 'msmc_curve_data',\n",
       " 'requirements.txt',\n",
       " 'ARI_consistency_test4.py',\n",
       " 'msmc_meta_data',\n",
       " 'Silhouette_analysis.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a6b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARI_test_dict_oldSeed1263.pkl',\n",
       " 'ARI_test_dict_oldSeed1538.pkl',\n",
       " 'ARI_test_dict_oldSeed1559.pkl',\n",
       " 'ARI_test_dict_oldSeed1660.pkl',\n",
       " 'ARI_test_dict_oldSeed1840.pkl',\n",
       " 'ARI_test_dict_oldSeed2127.pkl',\n",
       " 'ARI_test_dict_oldSeed2188.pkl',\n",
       " 'ARI_test_dict_oldSeed2233.pkl',\n",
       " 'ARI_test_dict_oldSeed2378.pkl',\n",
       " 'ARI_test_dict_oldSeed2463.pkl',\n",
       " 'ARI_test_dict_oldSeed3411.pkl',\n",
       " 'ARI_test_dict_oldSeed3483.pkl',\n",
       " 'ARI_test_dict_oldSeed3511.pkl',\n",
       " 'ARI_test_dict_oldSeed4803.pkl',\n",
       " 'ARI_test_dict_oldSeed4830.pkl',\n",
       " 'ARI_test_dict_oldSeed4889.pkl',\n",
       " 'ARI_test_dict_oldSeed5174.pkl',\n",
       " 'ARI_test_dict_oldSeed5179.pkl',\n",
       " 'ARI_test_dict_oldSeed5209.pkl',\n",
       " 'ARI_test_dict_oldSeed5299.pkl',\n",
       " 'ARI_test_dict_oldSeed5345.pkl',\n",
       " 'ARI_test_dict_oldSeed5604.pkl',\n",
       " 'ARI_test_dict_oldSeed5649.pkl',\n",
       " 'ARI_test_dict_oldSeed6191.pkl',\n",
       " 'ARI_test_dict_oldSeed6305.pkl',\n",
       " 'ARI_test_dict_oldSeed6740.pkl',\n",
       " 'ARI_test_dict_oldSeed698.pkl',\n",
       " 'ARI_test_dict_oldSeed7496.pkl',\n",
       " 'ARI_test_dict_oldSeed7718.pkl',\n",
       " 'ARI_test_dict_oldSeed7878.pkl',\n",
       " 'ARI_test_dict_oldSeed8437.pkl',\n",
       " 'ARI_test_dict_oldSeed8705.pkl',\n",
       " 'ARI_test_dict_oldSeed8802.pkl',\n",
       " 'ARI_test_dict_oldSeed8978.pkl',\n",
       " 'ARI_test_dict_oldSeed9166.pkl',\n",
       " 'ARI_test_dict_oldSeed9191.pkl',\n",
       " 'ARI_test_dict_oldSeed9266.pkl',\n",
       " 'ARI_test_dict_oldSeed9593.pkl',\n",
       " 'ARI_test_dict_oldSeed963.pkl',\n",
       " 'ARI_test_dict_oldSeed9778.pkl',\n",
       " 'additionalOmissions',\n",
       " 'badVoteFig_oldSeed1263.png',\n",
       " 'badVoteFig_oldSeed1538.png',\n",
       " 'badVoteFig_oldSeed1559.png',\n",
       " 'badVoteFig_oldSeed1660.png',\n",
       " 'badVoteFig_oldSeed1840.png',\n",
       " 'badVoteFig_oldSeed2127.png',\n",
       " 'badVoteFig_oldSeed2188.png',\n",
       " 'badVoteFig_oldSeed2233.png',\n",
       " 'badVoteFig_oldSeed2378.png',\n",
       " 'badVoteFig_oldSeed2463.png',\n",
       " 'badVoteFig_oldSeed3411.png',\n",
       " 'badVoteFig_oldSeed3483.png',\n",
       " 'badVoteFig_oldSeed3511.png',\n",
       " 'badVoteFig_oldSeed4803.png',\n",
       " 'badVoteFig_oldSeed4830.png',\n",
       " 'badVoteFig_oldSeed4889.png',\n",
       " 'badVoteFig_oldSeed5174.png',\n",
       " 'badVoteFig_oldSeed5179.png',\n",
       " 'badVoteFig_oldSeed5209.png',\n",
       " 'badVoteFig_oldSeed5299.png',\n",
       " 'badVoteFig_oldSeed5345.png',\n",
       " 'badVoteFig_oldSeed5604.png',\n",
       " 'badVoteFig_oldSeed5649.png',\n",
       " 'badVoteFig_oldSeed6191.png',\n",
       " 'badVoteFig_oldSeed6305.png',\n",
       " 'badVoteFig_oldSeed6740.png',\n",
       " 'badVoteFig_oldSeed698.png',\n",
       " 'badVoteFig_oldSeed7496.png',\n",
       " 'badVoteFig_oldSeed7718.png',\n",
       " 'badVoteFig_oldSeed7878.png',\n",
       " 'badVoteFig_oldSeed8437.png',\n",
       " 'badVoteFig_oldSeed8705.png',\n",
       " 'badVoteFig_oldSeed8802.png',\n",
       " 'badVoteFig_oldSeed8978.png',\n",
       " 'badVoteFig_oldSeed9166.png',\n",
       " 'badVoteFig_oldSeed9191.png',\n",
       " 'badVoteFig_oldSeed9266.png',\n",
       " 'badVoteFig_oldSeed9593.png',\n",
       " 'badVoteFig_oldSeed963.png',\n",
       " 'badVoteFig_oldSeed9778.png',\n",
       " 'badVote_oldSeed1263.pkl',\n",
       " 'badVote_oldSeed1538.pkl',\n",
       " 'badVote_oldSeed1559.pkl',\n",
       " 'badVote_oldSeed1660.pkl',\n",
       " 'badVote_oldSeed1840.pkl',\n",
       " 'badVote_oldSeed2127.pkl',\n",
       " 'badVote_oldSeed2188.pkl',\n",
       " 'badVote_oldSeed2233.pkl',\n",
       " 'badVote_oldSeed2378.pkl',\n",
       " 'badVote_oldSeed2463.pkl',\n",
       " 'badVote_oldSeed3411.pkl',\n",
       " 'badVote_oldSeed3483.pkl',\n",
       " 'badVote_oldSeed3511.pkl',\n",
       " 'badVote_oldSeed4803.pkl',\n",
       " 'badVote_oldSeed4830.pkl',\n",
       " 'badVote_oldSeed4889.pkl',\n",
       " 'badVote_oldSeed5174.pkl',\n",
       " 'badVote_oldSeed5179.pkl',\n",
       " 'badVote_oldSeed5209.pkl',\n",
       " 'badVote_oldSeed5299.pkl',\n",
       " 'badVote_oldSeed5345.pkl',\n",
       " 'badVote_oldSeed5604.pkl',\n",
       " 'badVote_oldSeed5649.pkl',\n",
       " 'badVote_oldSeed6191.pkl',\n",
       " 'badVote_oldSeed6305.pkl',\n",
       " 'badVote_oldSeed6740.pkl',\n",
       " 'badVote_oldSeed698.pkl',\n",
       " 'badVote_oldSeed7496.pkl',\n",
       " 'badVote_oldSeed7718.pkl',\n",
       " 'badVote_oldSeed7878.pkl',\n",
       " 'badVote_oldSeed8437.pkl',\n",
       " 'badVote_oldSeed8705.pkl',\n",
       " 'badVote_oldSeed8802.pkl',\n",
       " 'badVote_oldSeed8978.pkl',\n",
       " 'badVote_oldSeed9166.pkl',\n",
       " 'badVote_oldSeed9191.pkl',\n",
       " 'badVote_oldSeed9266.pkl',\n",
       " 'badVote_oldSeed9593.pkl',\n",
       " 'badVote_oldSeed963.pkl',\n",
       " 'badVote_oldSeed9778.pkl',\n",
       " 'finalARI_test_dict_oldSeed999.pkl',\n",
       " 'finalOmitsList.txt',\n",
       " 'final_ARI_boxplot.png',\n",
       " 'final_ARIs.csv',\n",
       " 'finalbadVoteFig_oldSeed999.png',\n",
       " 'finalbadVote_oldSeed999.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get into batches_40_trials_cutoff_last_5.100_samples/ and grab each of the:\n",
    "- ARI_test_dict_oldSeed{XXXX}.pkl\n",
    "    - Go to \"MSMC-Exploratory-Analysis/results/consistency-tests/ARI_testing/\"\n",
    "'''\n",
    "path = \"MSMC-Exploratory-Analysis/results/consistency-tests/ARI_testing/\"\n",
    "thegood = \"batches_40_trials_20_cutoff_last_5.100_samples/\"\n",
    "sorted(os.listdir(path+thegood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64a7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pickle = \"finalARI_test_dict_oldSeed999.pkl\"\n",
    "finalARI_test_dict = pickle.load(open(path+thegood+final_pickle, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b0a31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Get Erik a list of the best performing sample omission list\n",
    "- Along with that list, send him a table of (samples, seed_iters) = label\n",
    "- Also get him that time series dataframe\n",
    "    1.) With all normalized data\n",
    "    2.) With best performing normalized data\n",
    "\n",
    "finalARI_test_dict[gamma] is list of len 5\n",
    "\n",
    "Recall:\n",
    "by_gamma_dict[gamma] = [old_seed_dict,\n",
    "                        new_seed_dict,\n",
    "                        randi_dict,\n",
    "                        old_clusters,\n",
    "                        new_clusters]\n",
    "'''\n",
    "# This contains cluster labels of each clustering on seed 999, which is used\n",
    "# for comparison. Something dumb: I pasted the same thing into the dict for\n",
    "# each trial :-p\n",
    "seed999clusterlabels = finalARI_test_dict[0.0][0]\n",
    "finalARI_test_dict[0.0][4][8][944].dtw_labels\n",
    "oldSeedMC = finalARI_test_dict[0.0][3][8][999]\n",
    "newSeedsMC = finalARI_test_dict[0.0][4][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb2f47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rows will be samples, columns will be iteration/seed id\n",
    "'''\n",
    "write_path = 'MSMC-Exploratory-Analysis/results/consistency-tests/'\n",
    "bestLabelTableName = \"best_sample_label_assignments.csv\"\n",
    "newSeedsMC_data_dict = {item[0]: item[1].dtw_labels for item in newSeedsMC.items()}\n",
    "cols_and_keys = list(newSeedsMC_data_dict.keys())\n",
    "rows = oldSeedMC.namesofMySeries\n",
    "cols = cols_and_keys\n",
    "best_sample_label_df = pd.DataFrame(columns=cols, index=rows)\n",
    "for key in cols_and_keys:\n",
    "    best_sample_label_df[key] = newSeedsMC_data_dict[key]\n",
    "best_sample_label_df.columns = list(range(len(cols_and_keys)))\n",
    "\n",
    "# best_sample_label_df.to_csv(write_path+bestLabelTableName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98864a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sample_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "350449b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pd.read_csv(write_path+bestLabelTableName, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a60221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47803242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stats]",
   "language": "python",
   "name": "conda-env-stats-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
